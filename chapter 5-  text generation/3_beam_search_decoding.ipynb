{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhjsaoUJ1m4R",
        "outputId": "344f2269-2755-4783-8698-f4372eb77169"
      },
      "id": "QhjsaoUJ1m4R",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def log_probs_from_logits(logits, labels):\n",
        "  logp = F. log_softmax(logits, dim=- 1)\n",
        "  logp_label = torch.gather(logp, 2, labels. unsqueeze(2)). squeeze(- 1)\n",
        "  return logp_label"
      ],
      "metadata": {
        "id": "CUV1Is3IGMW1"
      },
      "id": "CUV1Is3IGMW1",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_logprob(model, labels, input_len=0):\n",
        "  with torch.no_grad():\n",
        "    output = model(labels)\n",
        "    log_probs = log_probs_from_logits(output.logits[:, : - 1, :], labels[:, 1:])\n",
        "    seq_log_prob = torch.sum(log_probs[:, input_len:])\n",
        "  return seq_log_prob.cpu().numpy()\n"
      ],
      "metadata": {
        "id": "CWNEI1TxGMZm"
      },
      "id": "CWNEI1TxGMZm",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "device = \"cuda\" if torch. cuda. is_available() else \"cpu\"\n",
        "model_name = \"gpt2-xl\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "max_length = 128\n",
        "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
        "a herd of unicorns living in a remote, previously unexplored \\\n",
        "valley, in the Andes Mountains. Even more surprising to the \\\n",
        "researchers was the fact that the unicorns spoke perfect English. \\n\\n\n",
        "\"\"\"\n",
        "input_ids = tokenizer(input_txt, return_tensors=\"pt\" )[\"input_ids\" ].to(device)\n",
        "output_greedy = model.generate(input_ids, max_length=max_length, do_sample=False)\n",
        "\n",
        "logp = sequence_logprob(model, output_greedy, input_len=len(input_ids[0]))\n",
        "print(tokenizer.decode(output_greedy[0]))\n",
        "print(f\" \\nlog-prob: {logp:.2f}\" )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdaM5jelGMb-",
        "outputId": "d5324edc-e059-4919-be55-592243765370"
      },
      "id": "qdaM5jelGMb-",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. \n",
            "\n",
            "\n",
            "The researchers, from the University of California, Davis, and the University of Colorado, Boulder, were conducting a study on the Andean cloud forest, which is home to the rare species of cloud forest trees. \n",
            "\n",
            "\n",
            "The researchers were conducting a study on the Andean cloud forest, which is home to the rare species of cloud forest trees. \n",
            "\n",
            "\n",
            "The researchers were conducting a study on\n",
            " \n",
            "log-prob: -68.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_beam = model.generate(input_ids,\n",
        "                              max_length=max_length,\n",
        "                              num_beams=5,\n",
        "                              do_sample=False)\n",
        "\n",
        "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
        "\n",
        "print(tokenizer. decode(output_beam[0]))\n",
        "print(f\" \\nlog-prob: {logp:.2f}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGkUj8lsGMeu",
        "outputId": "4c15ce8b-13ec-4e97-c094-d59062881910"
      },
      "id": "lGkUj8lsGMeu",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. \n",
            "\n",
            "\n",
            "According to the researchers, the unicorns were found in a remote valley in the Andes Mountains in Peru. The valley is located in a remote area of the Andes Mountains. The valley is located in a remote area of the Andes Mountains. According to the researchers, the unicorns were found in a remote valley in the Andes Mountains in Peru. The valley is located in a remote area\n",
            " \n",
            "log-prob: -44.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_beam = model.generate(input_ids,\n",
        "                              max_length=max_length,\n",
        "                              num_beams=5,\n",
        "                              do_sample=False,\n",
        "                              no_repeat_ngram_size=2)\n",
        "\n",
        "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
        "\n",
        "print(tokenizer.decode(output_beam[0]))\n",
        "print(f\" \\nlog-prob: {logp:.2f}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FJ7eKiEGMg8",
        "outputId": "8d92cb53-91d7-49b6-95e6-be09bd717c87"
      },
      "id": "7FJ7eKiEGMg8",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. \n",
            "\n",
            "\n",
            "The researchers, from the University of California, Los Angeles (UCLA) and the Universidad Nacional Autónoma de México (UNAM) in Mexico City, discovered the unicorn herd by accident. They were conducting a study on the effects of climate change on wild animals, when they came across the herd.\n",
            "\n",
            "\"When we first saw them, we couldn't believe our\n",
            " \n",
            "log-prob: -77.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VuXIunJCGMly"
      },
      "id": "VuXIunJCGMly",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MN8XhgqbGMoY"
      },
      "id": "MN8XhgqbGMoY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}